{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.svm import SVR, NuSVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we run the sript to generate all the variables we'll use\n",
    "\n",
    "# Generate train file\n",
    "#%run ../scripts/create_variables.py -f ../data/train.csv -c excerpt -nc cleaned_text -nf processed_analysed_train.csv\n",
    "# Generate test file\n",
    "#%run ../scripts/create_variables.py -f ../data/test.csv -c excerpt -nc cleaned_text -nf processed_analysed_test.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next we read the data\n",
    "train_df = pd.read_csv('../data/outputs/processed_analysed_train.csv')\n",
    "test_df = pd.read_csv('../data/outputs/processed_analysed_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   friend  alway     light  you  name   end  carri  set  though  need  ...  \\\n",
       "0     0.0    0.0  0.076923  0.0   0.0  0.75    0.0  0.0     0.0   0.0  ...   \n",
       "1     0.0    0.0  0.000000  0.0   0.0  0.00    0.0  0.0     0.0   0.0  ...   \n",
       "2     0.0    0.0  0.000000  0.2   0.0  0.00    0.0  0.0     0.0   0.0  ...   \n",
       "3     0.0    0.0  0.000000  0.0   0.0  0.25    0.0  0.0     0.0   0.0  ...   \n",
       "4     0.0    0.0  0.000000  0.0   0.0  0.00    0.0  0.0     0.0   0.0  ...   \n",
       "\n",
       "   sentence_count  sentence_score  rd_automatedindex  rd_fogscale  \\\n",
       "0              11          1.3431                8.3         8.31   \n",
       "1              12          1.5504                7.2         7.53   \n",
       "2               8          1.0710               10.1        10.49   \n",
       "3               5          0.6693               16.4        13.61   \n",
       "4               5          0.8666               11.8        11.76   \n",
       "\n",
       "   rd_colemanliau  rd_flesch_ease  rd_linearwrite  rd_fleschkincaid_grade  \\\n",
       "0            8.06           80.31        9.000000                     6.1   \n",
       "1            6.78           82.54        7.285714                     5.2   \n",
       "2            7.20           75.74       14.750000                     7.9   \n",
       "3            8.54           72.02       12.500000                    11.4   \n",
       "4            4.83           75.47       13.500000                    10.0   \n",
       "\n",
       "   rd_dalechall  rd_consensus  \n",
       "0          6.65           9.0  \n",
       "1          5.92           8.0  \n",
       "2          6.29           8.0  \n",
       "3          6.61           7.0  \n",
       "4          1.57          12.0  \n",
       "\n",
       "[5 rows x 514 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>friend</th>\n      <th>alway</th>\n      <th>light</th>\n      <th>you</th>\n      <th>name</th>\n      <th>end</th>\n      <th>carri</th>\n      <th>set</th>\n      <th>though</th>\n      <th>need</th>\n      <th>...</th>\n      <th>sentence_count</th>\n      <th>sentence_score</th>\n      <th>rd_automatedindex</th>\n      <th>rd_fogscale</th>\n      <th>rd_colemanliau</th>\n      <th>rd_flesch_ease</th>\n      <th>rd_linearwrite</th>\n      <th>rd_fleschkincaid_grade</th>\n      <th>rd_dalechall</th>\n      <th>rd_consensus</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.076923</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.75</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>11</td>\n      <td>1.3431</td>\n      <td>8.3</td>\n      <td>8.31</td>\n      <td>8.06</td>\n      <td>80.31</td>\n      <td>9.000000</td>\n      <td>6.1</td>\n      <td>6.65</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>12</td>\n      <td>1.5504</td>\n      <td>7.2</td>\n      <td>7.53</td>\n      <td>6.78</td>\n      <td>82.54</td>\n      <td>7.285714</td>\n      <td>5.2</td>\n      <td>5.92</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.2</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>8</td>\n      <td>1.0710</td>\n      <td>10.1</td>\n      <td>10.49</td>\n      <td>7.20</td>\n      <td>75.74</td>\n      <td>14.750000</td>\n      <td>7.9</td>\n      <td>6.29</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.25</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>5</td>\n      <td>0.6693</td>\n      <td>16.4</td>\n      <td>13.61</td>\n      <td>8.54</td>\n      <td>72.02</td>\n      <td>12.500000</td>\n      <td>11.4</td>\n      <td>6.61</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>5</td>\n      <td>0.8666</td>\n      <td>11.8</td>\n      <td>11.76</td>\n      <td>4.83</td>\n      <td>75.47</td>\n      <td>13.500000</td>\n      <td>10.0</td>\n      <td>1.57</td>\n      <td>12.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 514 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# Create the variables to predict and to train with\n",
    "drop_feat = ['excerpt', 'cleaned_text', 'id', 'standard_error', 'target', 'url_legal', 'license']\n",
    "X = train_df.drop(drop_feat, axis=1)\n",
    "y = train_df['target']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVR models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We leave out 'linear' and 'sigmoid' due to their bad results\n",
    "svr_kernels = ['poly', 'rbf']\n",
    "#gamma = np.arange(0.1, 1, 0.4)\n",
    "gam=0.1\n",
    "\n",
    "svr_pred =\\\n",
    "    [SVR(kernel=ker, C=100, gamma=gam, degree=3, epsilon=.1, coef0=1).fit(X, y).predict(X)\\\n",
    "     for ker in svr_kernels]\n",
    "\n",
    "svr_acc = [mean_squared_error(y, y_pred) for y_pred in svr_pred]\n",
    "\n",
    "#display([(ker, gam, acc) for ker in svr_kernels for gam in gamma for acc in svr_acc\\\n",
    "#         if acc <= 0.01])\n",
    "\n",
    "for ker, acc in list(zip(svr_kernels, svr_acc)):\n",
    "    print(ker + \": \" + str(acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NuSVR models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nusvr_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "\n",
    "nusvr_pred =\\\n",
    "    [NuSVR(kernel=ker, C=100, gamma=0.1, degree=3, nu=.1, coef0=1).fit(X, y).predict(X)\\\n",
    "     for ker in nusvr_kernels]\n",
    "\n",
    "nusvr_acc = [mean_squared_error(y, y_pred) for y_pred in nusvr_pred]\n",
    "\n",
    "for ker, acc in list(zip(nusvr_kernels, nusvr_acc)):\n",
    "    print(ker + \": \" + str(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's separate the training data into train and test data\n",
    "data_train, data_val, target_train, target_val = \\\n",
    "    train_test_split(train_df, train_df[\"target\"], test_size=0.3, random_state=5)\n",
    "\n",
    "# As before, drop irrelevant features or features that we do not need\n",
    "X_train = data_train.drop(drop_feat, axis=1)\n",
    "X_val = data_val.drop(drop_feat, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mean Squared Error: 0.6471750555617857\n"
     ]
    }
   ],
   "source": [
    "xgbreg = XGBRegressor()\n",
    "xgbreg.fit(X_train, target_train)\n",
    "\n",
    "kfold = KFold(n_splits=5, random_state=7, shuffle=True)\n",
    "results = cross_val_score(xgbreg, X_train, target_train, cv=kfold)\n",
    "\n",
    "y_test_pred = xgbreg.predict(X_val)\n",
    "mse = mean_squared_error(y_test_pred, target_val)\n",
    "print(\"Mean Squared Error: \" + str(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_df.drop(['id', 'url_legal', 'license', 'excerpt', 'cleaned_text'], axis=1)\n",
    "train.head()\n",
    "# Remove the targets from the set\n",
    "# Convert pandas df to np arrays\n",
    "targets = np.array(train['target'])\n",
    "feats = train.drop(['target'], axis=1)\n",
    "features_list = list(feats.columns)\n",
    "features = np.array(feats)\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.2, random_state=20)\n",
    "#### NOTE! I'm setting random_state to 20 so we get the same results every time we run the split.\n",
    "#### Results are reproducible, but maybe this is not the best approach\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Features Shape: (2267, 515)\nTraining Labels Shape: (2267,)\nTesting Features Shape: (567, 515)\nTesting Labels Shape: (567,)\n"
     ]
    }
   ],
   "source": [
    "# Sanity check: we expect the training features number of columns to match the testing feature number of columns \n",
    "# and the number of rows to match for the respective training and testing features and the labels\n",
    "print('Training Features Shape:', X_train.shape)\n",
    "print('Training Labels Shape:', y_train.shape)\n",
    "print('Testing Features Shape:', X_test.shape)\n",
    "print('Testing Labels Shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model with 1000 decision trees\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 20)\n",
    "#### NOTE! random_state again\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mean Absolute Error (MAE): 0.5254135828139506\nMean Squared Error (MSE): 0.5259818403639591\nRoot Mean Squared Error (RMSE): 0.7252460550488773\n"
     ]
    }
   ],
   "source": [
    "# Compute performance\n",
    "print('Mean Absolute Error (MAE):', metrics.mean_absolute_error(y_test, pred))\n",
    "print('Mean Squared Error (MSE):', metrics.mean_squared_error(y_test, pred))\n",
    "print('Root Mean Squared Error (RMSE):', np.sqrt(metrics.mean_squared_error(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Variable: rd_dalechall        0.36\nVariable: standard_error      0.21\nVariable: lexicon_count       0.02\nVariable: rd_fogscale         0.02\nVariable: rd_linearwrite      0.02\nVariable: brain               0.01\nVariable: punctuation_count   0.01\nVariable: punctuation_score   0.01\nVariable: lexicon_score       0.01\nVariable: sentence_score      0.01\nVariable: rd_automatedindex   0.01\nVariable: rd_colemanliau      0.01\nVariable: rd_flesch_ease      0.01\nVariable: rd_fleschkincaid_grade0.01\nVariable: friend              0.0\nVariable: alway               0.0\nVariable: light               0.0\nVariable: you                 0.0\nVariable: name                0.0\nVariable: end                 0.0\nVariable: carri               0.0\nVariable: set                 0.0\nVariable: though              0.0\nVariable: need                0.0\nVariable: that                0.0\nVariable: right               0.0\nVariable: night               0.0\nVariable: young               0.0\nVariable: quit                0.0\nVariable: let                 0.0\nVariable: not                 0.0\nVariable: known               0.0\nVariable: hard                0.0\nVariable: play                0.0\nVariable: far                 0.0\nVariable: big                 0.0\nVariable: start               0.0\nVariable: high                0.0\nVariable: togeth              0.0\nVariable: pass                0.0\nVariable: follow              0.0\nVariable: import              0.0\nVariable: men                 0.0\nVariable: walk                0.0\nVariable: left                0.0\nVariable: morn                0.0\nVariable: word                0.0\nVariable: tell                0.0\nVariable: noth                0.0\nVariable: show                0.0\nVariable: face                0.0\nVariable: got                 0.0\nVariable: children            0.0\nVariable: tree                0.0\nVariable: chang               0.0\nVariable: there               0.0\nVariable: along               0.0\nVariable: seen                0.0\nVariable: run                 0.0\nVariable: tri                 0.0\nVariable: mother              0.0\nVariable: almost              0.0\nVariable: heard               0.0\nVariable: natur               0.0\nVariable: sever               0.0\nVariable: close               0.0\nVariable: power               0.0\nVariable: her                 0.0\nVariable: keep                0.0\nVariable: knew                0.0\nVariable: anim                0.0\nVariable: leav                0.0\nVariable: told                0.0\nVariable: exampl              0.0\nVariable: someth              0.0\nVariable: white               0.0\nVariable: present             0.0\nVariable: father              0.0\nVariable: person              0.0\nVariable: studi               0.0\nVariable: beauti              0.0\nVariable: human               0.0\nVariable: yet                 0.0\nVariable: up                  0.0\nVariable: sometim             0.0\nVariable: next                0.0\nVariable: enough              0.0\nVariable: reach               0.0\nVariable: move                0.0\nVariable: room                0.0\nVariable: me                  0.0\nVariable: air                 0.0\nVariable: cri                 0.0\nVariable: point               0.0\nVariable: certain             0.0\nVariable: girl                0.0\nVariable: care                0.0\nVariable: do                  0.0\nVariable: whole               0.0\nVariable: now                 0.0\nVariable: ever                0.0\nVariable: but                 0.0\nVariable: gave                0.0\nVariable: happen              0.0\nVariable: can                 0.0\nVariable: usual               0.0\nVariable: direct              0.0\nVariable: sinc                0.0\nVariable: love                0.0\nVariable: caus                0.0\nVariable: becom               0.0\nVariable: order               0.0\nVariable: bodi                0.0\nVariable: stop                0.0\nVariable: again               0.0\nVariable: becam               0.0\nVariable: so                  0.0\nVariable: this                0.0\nVariable: matter              0.0\nVariable: learn               0.0\nVariable: out                 0.0\nVariable: war                 0.0\nVariable: land                0.0\nVariable: among               0.0\nVariable: general             0.0\nVariable: eat                 0.0\nVariable: sat                 0.0\nVariable: four                0.0\nVariable: door                0.0\nVariable: common              0.0\nVariable: earth               0.0\nVariable: stood               0.0\nVariable: sun                 0.0\nVariable: done                0.0\nVariable: includ              0.0\nVariable: number              0.0\nVariable: the                 0.0\nVariable: is                  0.0\nVariable: cours               0.0\nVariable: full                0.0\nVariable: hour                0.0\nVariable: ground              0.0\nVariable: food                0.0\nVariable: school              0.0\nVariable: dark                0.0\nVariable: mr                  0.0\nVariable: return              0.0\nVariable: feet                0.0\nVariable: system              0.0\nVariable: feel                0.0\nVariable: believ              0.0\nVariable: second              0.0\nVariable: all                 0.0\nVariable: better              0.0\nVariable: behind              0.0\nVariable: famili              0.0\nVariable: talk                0.0\nVariable: sound               0.0\nVariable: cover               0.0\nVariable: case                0.0\nVariable: given               0.0\nVariable: red                 0.0\nVariable: possibl             0.0\nVariable: in                  0.0\nVariable: sit                 0.0\nVariable: too                 0.0\nVariable: process             0.0\nVariable: then                0.0\nVariable: best                0.0\nVariable: less                0.0\nVariable: mind                0.0\nVariable: fall                0.0\nVariable: round               0.0\nVariable: sea                 0.0\nVariable: contain             0.0\nVariable: within              0.0\nVariable: strong              0.0\nVariable: ran                 0.0\nVariable: result              0.0\nVariable: heart               0.0\nVariable: allow               0.0\nVariable: organ               0.0\nVariable: watch               0.0\nVariable: busi                0.0\nVariable: taken               0.0\nVariable: earli               0.0\nVariable: rest                0.0\nVariable: produc              0.0\nVariable: wood                0.0\nVariable: river               0.0\nVariable: king                0.0\nVariable: plant               0.0\nVariable: continu             0.0\nVariable: build               0.0\nVariable: rather              0.0\nVariable: stand               0.0\nVariable: interest            0.0\nVariable: on                  0.0\nVariable: bird                0.0\nVariable: poor                0.0\nVariable: appear              0.0\nVariable: field               0.0\nVariable: wonder              0.0\nVariable: black               0.0\nVariable: abl                 0.0\nVariable: sudden              0.0\nVariable: clear               0.0\nVariable: although            0.0\nVariable: answer              0.0\nVariable: thus                0.0\nVariable: lay                 0.0\nVariable: toward              0.0\nVariable: group               0.0\nVariable: felt                0.0\nVariable: age                 0.0\nVariable: relat               0.0\nVariable: sure                0.0\nVariable: cold                0.0\nVariable: hold                0.0\nVariable: citi                0.0\nVariable: moment              0.0\nVariable: green               0.0\nVariable: fact                0.0\nVariable: fire                0.0\nVariable: develop             0.0\nVariable: kept                0.0\nVariable: wind                0.0\nVariable: grow                0.0\nVariable: brought             0.0\nVariable: short               0.0\nVariable: line                0.0\nVariable: travel              0.0\nVariable: read                0.0\nVariable: readi               0.0\nVariable: unit                0.0\nVariable: type                0.0\nVariable: half                0.0\nVariable: arm                 0.0\nVariable: except              0.0\nVariable: hear                0.0\nVariable: ago                 0.0\nVariable: remain              0.0\nVariable: experi              0.0\nVariable: window              0.0\nVariable: govern              0.0\nVariable: wait                0.0\nVariable: what                0.0\nVariable: oh                  0.0\nVariable: meet                0.0\nVariable: begin               0.0\nVariable: rememb              0.0\nVariable: later               0.0\nVariable: happi               0.0\nVariable: across              0.0\nVariable: today               0.0\nVariable: bring               0.0\nVariable: insid               0.0\nVariable: step                0.0\nVariable: street              0.0\nVariable: till                0.0\nVariable: piec                0.0\nVariable: effect              0.0\nVariable: enter               0.0\nVariable: bright              0.0\nVariable: realli              0.0\nVariable: term                0.0\nVariable: idea                0.0\nVariable: question            0.0\nVariable: either              0.0\nVariable: reason              0.0\nVariable: fill                0.0\nVariable: rock                0.0\nVariable: gone                0.0\nVariable: nt                  0.0\nVariable: lot                 0.0\nVariable: inform              0.0\nVariable: anyth               0.0\nVariable: five                0.0\nVariable: forc                0.0\nVariable: fine                0.0\nVariable: alon                0.0\nVariable: stori               0.0\nVariable: minut               0.0\nVariable: warm                0.0\nVariable: blue                0.0\nVariable: wide                0.0\nVariable: front               0.0\nVariable: dog                 0.0\nVariable: object              0.0\nVariable: wish                0.0\nVariable: bed                 0.0\nVariable: surfac              0.0\nVariable: road                0.0\nVariable: down                0.0\nVariable: amount              0.0\nVariable: hundr               0.0\nVariable: speak               0.0\nVariable: town                0.0\nVariable: grew                0.0\nVariable: everyth             0.0\nVariable: alreadi             0.0\nVariable: therefor            0.0\nVariable: top                 0.0\nVariable: requir              0.0\nVariable: child               0.0\nVariable: increas             0.0\nVariable: shall               0.0\nVariable: was                 0.0\nVariable: posit               0.0\nVariable: cell                0.0\nVariable: be                  0.0\nVariable: sent                0.0\nVariable: pretti              0.0\nVariable: held                0.0\nVariable: nation              0.0\nVariable: color               0.0\nVariable: visit               0.0\nVariable: lie                 0.0\nVariable: exist               0.0\nVariable: wall                0.0\nVariable: sky                 0.0\nVariable: quick               0.0\nVariable: provid              0.0\nVariable: cut                 0.0\nVariable: least               0.0\nVariable: voic                0.0\nVariable: forest              0.0\nVariable: understand          0.0\nVariable: garden              0.0\nVariable: similar             0.0\nVariable: receiv              0.0\nVariable: activ               0.0\nVariable: distanc             0.0\nVariable: particular          0.0\nVariable: entir               0.0\nVariable: here                0.0\nVariable: book                0.0\nVariable: whose               0.0\nVariable: fell                0.0\nVariable: besid               0.0\nVariable: longer              0.0\nVariable: centuri             0.0\nVariable: week                0.0\nVariable: thousand            0.0\nVariable: summer              0.0\nVariable: connect             0.0\nVariable: brother             0.0\nVariable: condit              0.0\nVariable: hors                0.0\nVariable: mile                0.0\nVariable: laugh               0.0\nVariable: lead                0.0\nVariable: creat               0.0\nVariable: purpos              0.0\nVariable: decid               0.0\nVariable: arriv               0.0\nVariable: villag              0.0\nVariable: materi              0.0\nVariable: success             0.0\nVariable: fear                0.0\nVariable: late                0.0\nVariable: main                0.0\nVariable: observ              0.0\nVariable: month               0.0\nVariable: american            0.0\nVariable: cross               0.0\nVariable: mountain            0.0\nVariable: origin              0.0\nVariable: deep                0.0\nVariable: led                 0.0\nVariable: slowli              0.0\nVariable: complet             0.0\nVariable: energi              0.0\nVariable: inde                0.0\nVariable: listen              0.0\nVariable: winter              0.0\nVariable: act                 0.0\nVariable: fli                 0.0\nVariable: space               0.0\nVariable: whether             0.0\nVariable: stone               0.0\nVariable: son                 0.0\nVariable: hope                0.0\nVariable: sort                0.0\nVariable: wave                0.0\nVariable: electr              0.0\nVariable: special             0.0\nVariable: region              0.0\nVariable: tabl                0.0\nVariable: strang              0.0\nVariable: pictur              0.0\nVariable: he                  0.0\nVariable: fast                0.0\nVariable: low                 0.0\nVariable: perhap              0.0\nVariable: write               0.0\nVariable: dress               0.0\nVariable: hair                0.0\nVariable: bear                0.0\nVariable: cloth               0.0\nVariable: stay                0.0\nVariable: befor               0.0\nVariable: scientist           0.0\nVariable: sleep               0.0\nVariable: grass               0.0\nVariable: hill                0.0\nVariable: protect             0.0\nVariable: consist             0.0\nVariable: paper               0.0\nVariable: which               0.0\nVariable: discov              0.0\nVariable: singl               0.0\nVariable: no                  0.0\nVariable: depend              0.0\nVariable: thick               0.0\nVariable: lost                0.0\nVariable: control             0.0\nVariable: for                 0.0\nVariable: soft                0.0\nVariable: practic             0.0\nVariable: seat                0.0\nVariable: histori             0.0\nVariable: final               0.0\nVariable: heat                0.0\nVariable: floor               0.0\nVariable: describ             0.0\nVariable: refer               0.0\nVariable: size                0.0\nVariable: surpris             0.0\nVariable: met                 0.0\nVariable: offic               0.0\nVariable: dear                0.0\nVariable: drop                0.0\nVariable: pick                0.0\nVariable: sister              0.0\nVariable: sight               0.0\nVariable: himself             0.0\nVariable: ladi                0.0\nVariable: break               0.0\nVariable: probabl             0.0\nVariable: we                  0.0\nVariable: consid              0.0\nVariable: occur               0.0\nVariable: die                 0.0\nVariable: bad                 0.0\nVariable: foot                0.0\nVariable: ship                0.0\nVariable: store               0.0\nVariable: instead             0.0\nVariable: money               0.0\nVariable: view                0.0\nVariable: dri                 0.0\nVariable: especi              0.0\nVariable: middl               0.0\nVariable: glad                0.0\nVariable: notic               0.0\nVariable: sens                0.0\nVariable: mrs                 0.0\nVariable: yes                 0.0\nVariable: or                  0.0\nVariable: free                0.0\nVariable: excit               0.0\nVariable: spring              0.0\nVariable: fish                0.0\nVariable: manner              0.0\nVariable: physic              0.0\nVariable: danger              0.0\nVariable: quiet               0.0\nVariable: true                0.0\nVariable: measur              0.0\nVariable: flower              0.0\nVariable: wife                0.0\nVariable: method              0.0\nVariable: pleas               0.0\nVariable: subject             0.0\nVariable: outsid              0.0\nVariable: hot                 0.0\nVariable: gather              0.0\nVariable: past                0.0\nVariable: babi                0.0\nVariable: master              0.0\nVariable: problem             0.0\nVariable: miss                0.0\nVariable: lower               0.0\nVariable: repli               0.0\nVariable: difficult           0.0\nVariable: rise                0.0\nVariable: area                0.0\nVariable: compani             0.0\nVariable: rule                0.0\nVariable: els                 0.0\nVariable: fair                0.0\nVariable: regard              0.0\nVariable: safe                0.0\nVariable: temperatur          0.0\nVariable: expect              0.0\nVariable: attent              0.0\nVariable: law                 0.0\nVariable: whi                 0.0\nVariable: various             0.0\nVariable: deal                0.0\nVariable: author              0.0\nVariable: current             0.0\nVariable: troubl              0.0\nVariable: star                0.0\nVariable: actual              0.0\nVariable: built               0.0\nVariable: rich                0.0\nVariable: europ               0.0\nVariable: mouth               0.0\nVariable: boat                0.0\nVariable: jump                0.0\nVariable: recent              0.0\nVariable: sentence_count      0.0\nVariable: rd_consensus        0.0\n"
     ]
    }
   ],
   "source": [
    "### MODEL ANALYSIS\n",
    "\n",
    "# Get numerical feature relevance\n",
    "importances = list(rf.feature_importances_)\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(features_list, importances)]\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True) \n",
    "for pair in feature_importances:\n",
    "    print('Variable: {:20}{}'.format(*pair))\n",
    "## All the word-variables related to the TF-IDF analysis don't seem to be relevant for the model.\n",
    "## We might assume that we don't need information from isolated words.\n",
    "## We can retest the model using only some of the readability measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = ['rd_dalechall', 'standard_error', 'lexicon_count', 'punctuation_count', 'rd_flesch_ease', 'rd_colemanliau', 'rd_fogscale']\n",
    "targets = np.array(train['target'])\n",
    "features = np.array(train[features_list])\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.2, random_state=20)\n",
    "#### NOTE! I'm setting random_state to 20 so we get the same results every time we run the split.\n",
    "#### Results are reproducible, but maybe this is not the best approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mean Absolute Error (MAE): 0.5460683148735698\nMean Squared Error (MSE): 0.5263316876956162\nRoot Mean Squared Error (RMSE): 0.7254872071205779\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 20)\n",
    "rf.fit(X_train, y_train)\n",
    "pred = rf.predict(X_test)\n",
    "# Compute performance\n",
    "print('Mean Absolute Error (MAE):', metrics.mean_absolute_error(y_test, pred))\n",
    "print('Mean Squared Error (MSE):', metrics.mean_squared_error(y_test, pred))\n",
    "print('Root Mean Squared Error (RMSE):', np.sqrt(metrics.mean_squared_error(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We get almost the same results with this version. However, the results are not yet optimal.\n",
    "## Needs more fine tuning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of a single tree\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot\n",
    "from IPython.core.display import Image, display\n",
    "\n",
    "tree = rf.estimators_[10]\n",
    "export_graphviz(tree, out_file = 'tree.dot', feature_names = features_list, rounded = True, precision = 1)\n",
    "(graph, ) = pydot.graph_from_dot_file('tree.dot')\n",
    "graph.write_png('tree.png')\n",
    "display(Image('tree.png', height=1700, width=29000, unconfined=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2834\n",
      "Model:                            GLM   Df Residuals:                     2826\n",
      "Model Family:                Gaussian   Df Model:                            7\n",
      "Link Function:               identity   Scale:                         0.69140\n",
      "Method:                          IRLS   Log-Likelihood:                -3494.3\n",
      "Date:                Wed, 16 Jun 2021   Deviance:                       1953.9\n",
      "Time:                        01:47:32   Pearson chi2:                 1.95e+03\n",
      "No. Iterations:                     3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          3.7802      0.498      7.591      0.000       2.804       4.756\n",
      "x1            -0.1939      0.015    -13.326      0.000      -0.222      -0.165\n",
      "x2            -2.2956      0.451     -5.091      0.000      -3.179      -1.412\n",
      "x3            -0.0089      0.001     -9.320      0.000      -0.011      -0.007\n",
      "x4             0.0026      0.002      1.488      0.137      -0.001       0.006\n",
      "x5            -0.0002      0.003     -0.074      0.941      -0.007       0.006\n",
      "x6            -0.0469      0.014     -3.266      0.001      -0.075      -0.019\n",
      "x7            -0.0355      0.008     -4.381      0.000      -0.051      -0.020\n",
      "==============================================================================\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 2834\n",
      "Model:                            GLM   Df Residuals:                     2826\n",
      "Model Family:                   Gamma   Df Model:                            7\n",
      "Link Function:          inverse_power   Scale:                          2.5631\n",
      "Method:                          IRLS   Log-Likelihood:                    nan\n",
      "Date:                Wed, 16 Jun 2021   Deviance:                       40520.\n",
      "Time:                        01:47:32   Pearson chi2:                 7.24e+03\n",
      "No. Iterations:                    10                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        -10.2366      0.367    -27.917      0.000     -10.955      -9.518\n",
      "x1             0.6810      0.024     28.374      0.000       0.634       0.728\n",
      "x2             1.7287      0.144     12.033      0.000       1.447       2.010\n",
      "x3             0.0113      0.001     17.175      0.000       0.010       0.013\n",
      "x4            -0.0079      0.002     -5.240      0.000      -0.011      -0.005\n",
      "x5             0.0187      0.002     10.332      0.000       0.015       0.022\n",
      "x6            -0.0116      0.006     -1.940      0.052      -0.023       0.000\n",
      "x7             0.0169      0.004      4.209      0.000       0.009       0.025\n",
      "==============================================================================\n",
      "/home/juan/anaconda3/envs/capstone/lib/python3.8/site-packages/statsmodels/genmod/generalized_linear_model.py:293: DomainWarning: The inverse_power link function does not respect the domain of the Gamma family.\n",
      "  warnings.warn((f\"The {type(family.link).__name__} link function \"\n",
      "/home/juan/anaconda3/envs/capstone/lib/python3.8/site-packages/statsmodels/genmod/families/family.py:735: RuntimeWarning: divide by zero encountered in log\n",
      "  ll_obs -= special.gammaln(weight_scale) + np.log(endog)\n",
      "/home/juan/anaconda3/envs/capstone/lib/python3.8/site-packages/statsmodels/genmod/families/family.py:735: RuntimeWarning: invalid value encountered in log\n",
      "  ll_obs -= special.gammaln(weight_scale) + np.log(endog)\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "features_list = ['rd_dalechall', 'standard_error', 'lexicon_count', 'punctuation_count', 'rd_flesch_ease', 'rd_colemanliau', 'rd_fogscale']\n",
    "endog = np.array(train['target'])\n",
    "exog = sm.add_constant(np.array(train[features_list]))\n",
    "\n",
    "glmGauss = sm.GLM(endog, exog, family=sm.families.Gaussian()).fit()\n",
    "glmGamma = sm.GLM(endog, exog, family=sm.families.Gamma()).fit()\n",
    "\n",
    "print(glmGauss.summary())\n",
    "print(glmGamma.summary())\n",
    "\n",
    "## Both models exhibit a very poor performance. Thus, we might discard them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions:\n",
    "\n",
    "We conclude that GLM is not valid to predict readability complexity, at least with the data that we have. On the other hand, Random Forest looks like a better alternative to GLM. Although not optimal, the results seem quite reasonable. The model would benefit from finding a way to take advantage from TF-IDF. If we look at the MSE, the results exhibit by the Random Forest are a little bit better than the XGBoost ones."
   ]
  },
  {
   "source": [
    "## Future work\n",
    "\n",
    "Since there is still plenty of time to the competition, a section on future work is in order.\n",
    "\n",
    "We have tested more traditional methods of dealing with NLP, howerver, recent advances have created a family of models which we have barely touhed and could yield promissing results.\n",
    "\n",
    "Such models are BERT (of which we have two simple scripts), RoBERTa, ALBERT... All based on BERT, which stands for Bidirectional Encoder Representations from Transformers.\n",
    "\n",
    "Thus, the natural course of action to take now is to explore such rich family of models and see which fits best our purouses."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python388jvsc74a57bd077c47b19504d4546481ca43af86f60920f0981a6c7d66131e1f0ca408fcd2e6d",
   "display_name": "Python 3.8.8 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}