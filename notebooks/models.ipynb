{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.svm import SVR, NuSVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we run the sript to generate all the variables we'll use\n",
    "\n",
    "# Generate train file\n",
    "#%run ../scripts/create_variables.py -f ../data/train.csv -c excerpt -nc cleaned_text -nf processed_analysed_train.csv\n",
    "# Generate test file\n",
    "#%run ../scripts/create_variables.py -f ../data/test.csv -c excerpt -nc cleaned_text -nf processed_analysed_test.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next we read the data\n",
    "train_df = pd.read_csv('../data/outputs/processed_analysed_train.csv')\n",
    "test_df = pd.read_csv('../data/outputs/processed_analysed_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>friend</th>\n",
       "      <th>alway</th>\n",
       "      <th>light</th>\n",
       "      <th>you</th>\n",
       "      <th>name</th>\n",
       "      <th>end</th>\n",
       "      <th>carri</th>\n",
       "      <th>set</th>\n",
       "      <th>though</th>\n",
       "      <th>need</th>\n",
       "      <th>...</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>sentence_score</th>\n",
       "      <th>rd_automatedindex</th>\n",
       "      <th>rd_fogscale</th>\n",
       "      <th>rd_colemanliau</th>\n",
       "      <th>rd_flesch_ease</th>\n",
       "      <th>rd_linearwrite</th>\n",
       "      <th>rd_fleschkincaid_grade</th>\n",
       "      <th>rd_dalechall</th>\n",
       "      <th>rd_consensus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>1.3431</td>\n",
       "      <td>8.3</td>\n",
       "      <td>8.31</td>\n",
       "      <td>8.06</td>\n",
       "      <td>80.31</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.1</td>\n",
       "      <td>6.65</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>1.5504</td>\n",
       "      <td>7.2</td>\n",
       "      <td>7.53</td>\n",
       "      <td>6.78</td>\n",
       "      <td>82.54</td>\n",
       "      <td>7.285714</td>\n",
       "      <td>5.2</td>\n",
       "      <td>5.92</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0710</td>\n",
       "      <td>10.1</td>\n",
       "      <td>10.49</td>\n",
       "      <td>7.20</td>\n",
       "      <td>75.74</td>\n",
       "      <td>14.750000</td>\n",
       "      <td>7.9</td>\n",
       "      <td>6.29</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6693</td>\n",
       "      <td>16.4</td>\n",
       "      <td>13.61</td>\n",
       "      <td>8.54</td>\n",
       "      <td>72.02</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>11.4</td>\n",
       "      <td>6.61</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8666</td>\n",
       "      <td>11.8</td>\n",
       "      <td>11.76</td>\n",
       "      <td>4.83</td>\n",
       "      <td>75.47</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.57</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 514 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   friend  alway     light  you  name   end  carri  set  though  need  ...  \\\n",
       "0     0.0    0.0  0.076923  0.0   0.0  0.75    0.0  0.0     0.0   0.0  ...   \n",
       "1     0.0    0.0  0.000000  0.0   0.0  0.00    0.0  0.0     0.0   0.0  ...   \n",
       "2     0.0    0.0  0.000000  0.2   0.0  0.00    0.0  0.0     0.0   0.0  ...   \n",
       "3     0.0    0.0  0.000000  0.0   0.0  0.25    0.0  0.0     0.0   0.0  ...   \n",
       "4     0.0    0.0  0.000000  0.0   0.0  0.00    0.0  0.0     0.0   0.0  ...   \n",
       "\n",
       "   sentence_count  sentence_score  rd_automatedindex  rd_fogscale  \\\n",
       "0              11          1.3431                8.3         8.31   \n",
       "1              12          1.5504                7.2         7.53   \n",
       "2               8          1.0710               10.1        10.49   \n",
       "3               5          0.6693               16.4        13.61   \n",
       "4               5          0.8666               11.8        11.76   \n",
       "\n",
       "   rd_colemanliau  rd_flesch_ease  rd_linearwrite  rd_fleschkincaid_grade  \\\n",
       "0            8.06           80.31        9.000000                     6.1   \n",
       "1            6.78           82.54        7.285714                     5.2   \n",
       "2            7.20           75.74       14.750000                     7.9   \n",
       "3            8.54           72.02       12.500000                    11.4   \n",
       "4            4.83           75.47       13.500000                    10.0   \n",
       "\n",
       "   rd_dalechall  rd_consensus  \n",
       "0          6.65           9.0  \n",
       "1          5.92           8.0  \n",
       "2          6.29           8.0  \n",
       "3          6.61           7.0  \n",
       "4          1.57          12.0  \n",
       "\n",
       "[5 rows x 514 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the variables to predict and to train with\n",
    "drop_feat = ['excerpt', 'cleaned_text', 'id', 'standard_error', 'target', 'url_legal', 'license']\n",
    "X = train_df.drop(drop_feat, axis=1)\n",
    "y = train_df['target']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVR models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We leave out 'linear' and 'sigmoid' due to their bad results\n",
    "svr_kernels = ['poly', 'rbf']\n",
    "#gamma = np.arange(0.1, 1, 0.4)\n",
    "gam=0.1\n",
    "\n",
    "svr_pred =\\\n",
    "    [SVR(kernel=ker, C=100, gamma=gam, degree=3, epsilon=.1, coef0=1).fit(X, y).predict(X)\\\n",
    "     for ker in svr_kernels]\n",
    "\n",
    "svr_acc = [mean_squared_error(y, y_pred) for y_pred in svr_pred]\n",
    "\n",
    "#display([(ker, gam, acc) for ker in svr_kernels for gam in gamma for acc in svr_acc\\\n",
    "#         if acc <= 0.01])\n",
    "\n",
    "for ker, acc in list(zip(svr_kernels, svr_acc)):\n",
    "    print(ker + \": \" + str(acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NuSVR models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nusvr_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "\n",
    "nusvr_pred =\\\n",
    "    [NuSVR(kernel=ker, C=100, gamma=0.1, degree=3, nu=.1, coef0=1).fit(X, y).predict(X)\\\n",
    "     for ker in nusvr_kernels]\n",
    "\n",
    "nusvr_acc = [mean_squared_error(y, y_pred) for y_pred in nusvr_pred]\n",
    "\n",
    "for ker, acc in list(zip(nusvr_kernels, nusvr_acc)):\n",
    "    print(ker + \": \" + str(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's separate the training data into train and test data\n",
    "data_train, data_val, target_train, target_val = \\\n",
    "    train_test_split(train_df, train_df[\"target\"], test_size=0.3, random_state=5)\n",
    "\n",
    "# As before, drop irrelevant features or features that we do not need\n",
    "X_train = data_train.drop(drop_feat, axis=1)\n",
    "X_val = data_val.drop(drop_feat, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbreg = XGBRegressor()\n",
    "xgbreg.fit(X_train, target_train)\n",
    "\n",
    "kfold = KFold(n_splits=5, random_state=7, shuffle=True)\n",
    "results = cross_val_score(xgbreg, X_train, target_train, cv=kfold)\n",
    "\n",
    "y_test_pred = xgbreg.predict(X_val)\n",
    "mse = mean_squared_error(y_test_pred, target_val)\n",
    "print(\"Mean Squared Error: \" + str(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_df.drop(['id', 'url_legal', 'license', 'excerpt', 'cleaned_text'], axis=1)\n",
    "train.head()\n",
    "# Remove the targets from the set\n",
    "# Convert pandas df to np arrays\n",
    "targets = np.array(train['target'])\n",
    "feats = train.drop(['target'], axis=1)\n",
    "features_list = list(feats.columns)\n",
    "features = np.array(feats)\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.2, random_state=20)\n",
    "#### NOTE! I'm setting random_state to 20 so we get the same results every time we run the split.\n",
    "#### Results are reproducible, but maybe this is not the best approach\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape: (2267, 515)\n",
      "Training Labels Shape: (2267,)\n",
      "Testing Features Shape: (567, 515)\n",
      "Testing Labels Shape: (567,)\n"
     ]
    }
   ],
   "source": [
    "# Sanity check: we expect the training features number of columns to match the testing feature number of columns \n",
    "# and the number of rows to match for the respective training and testing features and the labels\n",
    "print('Training Features Shape:', X_train.shape)\n",
    "print('Training Labels Shape:', y_train.shape)\n",
    "print('Testing Features Shape:', X_test.shape)\n",
    "print('Testing Labels Shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model with 1000 decision trees\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 20)\n",
    "#### NOTE! random_state again\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-fe1549c0b6eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Compute performance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mean Absolute Error (MAE):'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mean Squared Error (MSE):'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Root Mean Squared Error (RMSE):'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'metrics' is not defined"
     ]
    }
   ],
   "source": [
    "# Compute performance\n",
    "print('Mean Absolute Error (MAE):', metrics.mean_absolute_error(y_test, pred))\n",
    "print('Mean Squared Error (MSE):', metrics.mean_squared_error(y_test, pred))\n",
    "print('Root Mean Squared Error (RMSE):', np.sqrt(metrics.mean_squared_error(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MODEL ANALYSIS\n",
    "\n",
    "# Get numerical feature relevance\n",
    "importances = list(rf.feature_importances_)\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(features_list, importances)]\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True) \n",
    "for pair in feature_importances:\n",
    "    print('Variable: {:20}{}'.format(*pair))\n",
    "## All the word-variables related to the TF-IDF analysis don't seem to be relevant for the model.\n",
    "## We might assume that we don't need information from isolated words.\n",
    "## We can retest the model using only some of the readability measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = ['rd_dalechall', 'standard_error', 'lexicon_count', 'punctuation_count', 'rd_flesch_ease', 'rd_colemanliau', 'rd_fogscale']\n",
    "targets = np.array(train['target'])\n",
    "features = np.array(train[features_list])\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.2, random_state=20)\n",
    "#### NOTE! I'm setting random_state to 20 so we get the same results every time we run the split.\n",
    "#### Results are reproducible, but maybe this is not the best approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 20)\n",
    "rf.fit(X_train, y_train)\n",
    "pred = rf.predict(X_test)\n",
    "# Compute performance\n",
    "print('Mean Absolute Error (MAE):', metrics.mean_absolute_error(y_test, pred))\n",
    "print('Mean Squared Error (MSE):', metrics.mean_squared_error(y_test, pred))\n",
    "print('Root Mean Squared Error (RMSE):', np.sqrt(metrics.mean_squared_error(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We get almost the same results with this version. However, the results are not yet optimal.\n",
    "## Needs more fine tuning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of a single tree\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot\n",
    "from IPython.core.display import Image, display\n",
    "\n",
    "tree = rf.estimators_[10]\n",
    "export_graphviz(tree, out_file = 'tree.dot', feature_names = features_list, rounded = True, precision = 1)\n",
    "(graph, ) = pydot.graph_from_dot_file('tree.dot')\n",
    "graph.write_png('tree.png')\n",
    "display(Image('tree.png', height=1700, width=29000, unconfined=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "features_list = ['rd_dalechall', 'standard_error', 'lexicon_count', 'punctuation_count', 'rd_flesch_ease', 'rd_colemanliau', 'rd_fogscale']\n",
    "endog = np.array(train['target'])\n",
    "exog = sm.add_constant(np.array(train[features_list]))\n",
    "\n",
    "glmGauss = sm.GLM(endog, exog, family=sm.families.Gaussian()).fit()\n",
    "glmGamma = sm.GLM(endog, exog, family=sm.families.Gamma()).fit()\n",
    "\n",
    "print(glmGauss.summary())\n",
    "print(glmGamma.summary())\n",
    "\n",
    "## Both models exhibit a very poor performance. Thus, we might discard them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions:\n",
    "\n",
    "We conclude that GLM is not valid to predict readability complexity, at least with the data that we have. On the other hand, Random Forest looks like a better alternative to GLM. Although not optimal, the results seem quite reasonable. The model would benefit from finding a way to take advantage from TF-IDF. If we look at the MSE, the results exhibit by the Random Forest are a little bit better than the XGBoost ones."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
