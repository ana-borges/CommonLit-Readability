{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd077c47b19504d4546481ca43af86f60920f0981a6c7d66131e1f0ca408fcd2e6d",
   "display_name": "Python 3.8.8 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.svm import SVR, NuSVR\n",
    "\n",
    "from xgboost import XGBRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we run the sript to generate all the variables we'll use\n",
    "\n",
    "# Generate train file\n",
    "#%run ../scripts/create_variables.py -f ../data/train.csv -c excerpt -nc cleaned_text -nf processed_analysed_train.csv\n",
    "# Generate test file\n",
    "#%run ../scripts/create_variables.py -f ../data/test.csv -c excerpt -nc cleaned_text -nf processed_analysed_test.csv\n",
    "\n",
    "# Next we read the data\n",
    "train_df = pd.read_csv('../data/outputs/processed_analysed_train.csv')\n",
    "test_df = pd.read_csv('../data/outputs/processed_analysed_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   friend  alway     light  you  name   end  carri  set  though  need  ...  \\\n",
       "0     0.0    0.0  0.076923  0.0   0.0  0.75    0.0  0.0     0.0   0.0  ...   \n",
       "1     0.0    0.0  0.000000  0.0   0.0  0.00    0.0  0.0     0.0   0.0  ...   \n",
       "2     0.0    0.0  0.000000  0.2   0.0  0.00    0.0  0.0     0.0   0.0  ...   \n",
       "3     0.0    0.0  0.000000  0.0   0.0  0.25    0.0  0.0     0.0   0.0  ...   \n",
       "4     0.0    0.0  0.000000  0.0   0.0  0.00    0.0  0.0     0.0   0.0  ...   \n",
       "\n",
       "   sentence_count  sentence_score  rd_automatedindex  rd_fogscale  \\\n",
       "0              11          1.3431                8.3         8.31   \n",
       "1              12          1.5504                7.2         7.53   \n",
       "2               8          1.0710               10.1        10.49   \n",
       "3               5          0.6693               16.4        13.61   \n",
       "4               5          0.8666               11.8        11.76   \n",
       "\n",
       "   rd_colemanliau  rd_flesch_ease  rd_linearwrite  rd_fleschkincaid_grade  \\\n",
       "0            8.06           80.31        9.000000                     6.1   \n",
       "1            6.78           82.54        7.285714                     5.2   \n",
       "2            7.20           75.74       14.750000                     7.9   \n",
       "3            8.54           72.02       12.500000                    11.4   \n",
       "4            4.83           75.47       13.500000                    10.0   \n",
       "\n",
       "   rd_dalechall  rd_consensus  \n",
       "0          6.65           9.0  \n",
       "1          5.92           8.0  \n",
       "2          6.29           8.0  \n",
       "3          6.61           7.0  \n",
       "4          1.57          12.0  \n",
       "\n",
       "[5 rows x 514 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>friend</th>\n      <th>alway</th>\n      <th>light</th>\n      <th>you</th>\n      <th>name</th>\n      <th>end</th>\n      <th>carri</th>\n      <th>set</th>\n      <th>though</th>\n      <th>need</th>\n      <th>...</th>\n      <th>sentence_count</th>\n      <th>sentence_score</th>\n      <th>rd_automatedindex</th>\n      <th>rd_fogscale</th>\n      <th>rd_colemanliau</th>\n      <th>rd_flesch_ease</th>\n      <th>rd_linearwrite</th>\n      <th>rd_fleschkincaid_grade</th>\n      <th>rd_dalechall</th>\n      <th>rd_consensus</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.076923</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.75</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>11</td>\n      <td>1.3431</td>\n      <td>8.3</td>\n      <td>8.31</td>\n      <td>8.06</td>\n      <td>80.31</td>\n      <td>9.000000</td>\n      <td>6.1</td>\n      <td>6.65</td>\n      <td>9.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>12</td>\n      <td>1.5504</td>\n      <td>7.2</td>\n      <td>7.53</td>\n      <td>6.78</td>\n      <td>82.54</td>\n      <td>7.285714</td>\n      <td>5.2</td>\n      <td>5.92</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.2</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>8</td>\n      <td>1.0710</td>\n      <td>10.1</td>\n      <td>10.49</td>\n      <td>7.20</td>\n      <td>75.74</td>\n      <td>14.750000</td>\n      <td>7.9</td>\n      <td>6.29</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.25</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>5</td>\n      <td>0.6693</td>\n      <td>16.4</td>\n      <td>13.61</td>\n      <td>8.54</td>\n      <td>72.02</td>\n      <td>12.500000</td>\n      <td>11.4</td>\n      <td>6.61</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>5</td>\n      <td>0.8666</td>\n      <td>11.8</td>\n      <td>11.76</td>\n      <td>4.83</td>\n      <td>75.47</td>\n      <td>13.500000</td>\n      <td>10.0</td>\n      <td>1.57</td>\n      <td>12.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 514 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# Create the variables to predict and to train with\n",
    "drop_feat = ['excerpt', 'cleaned_text', 'id', 'standard_error', 'target', 'url_legal', 'license']\n",
    "X = train_df.drop(drop_feat, axis=1)\n",
    "y = train_df['target']\n",
    "X.head()"
   ]
  },
  {
   "source": [
    "### Support Vector Machines: SVR and NuSVR"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVR models\n",
    "\n",
    "# We leave out 'linear' and 'sigmoid' due to their bad results\n",
    "svr_kernels = ['poly', 'rbf']\n",
    "#gamma = np.arange(0.1, 1, 0.4)\n",
    "gam=0.1\n",
    "\n",
    "svr_pred =\\\n",
    "    [SVR(kernel=ker, C=100, gamma=gam, degree=3, epsilon=.1, coef0=1).fit(X, y).predict(X)\\\n",
    "     for ker in svr_kernels]\n",
    "\n",
    "svr_acc = [mean_squared_error(y, y_pred) for y_pred in svr_pred]\n",
    "\n",
    "#display([(ker, gam, acc) for ker in svr_kernels for gam in gamma for acc in svr_acc\\\n",
    "#         if acc <= 0.01])\n",
    "\n",
    "for ker, acc in list(zip(svr_kernels, svr_acc)):\n",
    "    print(ker + \": \" + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NuSVR models\n",
    "\n",
    "nusvr_kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "\n",
    "nusvr_pred =\\\n",
    "    [NuSVR(kernel=ker, C=100, gamma=0.1, degree=3, nu=.1, coef0=1).fit(X, y).predict(X)\\\n",
    "     for ker in nusvr_kernels]\n",
    "\n",
    "nusvr_acc = [mean_squared_error(y, y_pred) for y_pred in nusvr_pred]\n",
    "\n",
    "for ker, acc in list(zip(nusvr_kernels, nusvr_acc)):\n",
    "    print(ker + \": \" + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's separate the training data into train and test data\n",
    "data_train, data_val, target_train, target_val = \\\n",
    "    train_test_split(train_df, train_df[\"target\"], test_size=0.3, random_state=5)\n",
    "\n",
    "# As before, drop irrelevant features or features that we do not need\n",
    "X_train = data_train.drop(drop_feat, axis=1)\n",
    "X_val = data_val.drop(drop_feat, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbreg = XGBRegressor()\n",
    "xgbreg.fit(X_train, target_train)\n",
    "\n",
    "kfold = KFold(n_splits=5, random_state=7, shuffle=True)\n",
    "results = cross_val_score(xgbreg, X_train, target_train, cv=kfold)\n",
    "\n",
    "mse = mean_squared_error(y_test_pred, target_val)\n",
    "print(mse)"
   ]
  }
 ]
}